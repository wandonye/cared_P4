{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import heapq\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_imgs = [\"camera_cal/calibration\"+str(i)+\".jpg\" for i in range(1,21)]\n",
    "grid_sizes = [(9,5),(9,6),(9,6),(6,5),(7,6)]+ [(9,6)]*15\n",
    "\n",
    "def calibration_matrix(imgs, grid_sizes):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    for idx, fname in enumerate(imgs):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        grid_size = grid_sizes[idx]\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, grid_size, None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objp = np.zeros((grid_size[0]*grid_size[1],3), np.float32)\n",
    "            objp[:,:2] = np.mgrid[0:grid_size[0], 0:grid_size[1]].T.reshape(-1,2)\n",
    "\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (mtx,dist)\n",
    "\n",
    "mtx, dist = calibration_matrix(check_imgs,grid_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation to Birdview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (720,720)\n",
    "\n",
    "def perspective_transformation(target_img_size):\n",
    "    src = np.array([[592, 453], \n",
    "                    [695,453],\n",
    "                    [970, 630],\n",
    "                    [348, 630]], dtype = \"float32\")\n",
    "\n",
    "    h_margin = 200\n",
    "    top_margin = 200\n",
    "    bottom_margin = 30\n",
    "    dst = np.array([[h_margin, top_margin], \n",
    "                    [target_img_size[0] - h_margin, top_margin],\n",
    "                    [target_img_size[0] - h_margin, target_img_size[1] - bottom_margin],\n",
    "                    [h_margin, target_img_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "    return cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "M = perspective_transformation(img_size)\n",
    "M_inv = np.linalg.inv(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how the mask looks like on the birdview image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e4340f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFUNBUsVQkFQxFCRVDAVJFUNBUuX/AT0GwkrjCFqgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d578358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def region_of_interest(shape, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros(shape,dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, np.array([vertices], dtype=np.int32),1)\n",
    "    return mask\n",
    "roi = region_of_interest((720,1280), [[300,420],[200,670],[700,600],[1150,670],[1000,420]])\n",
    "roi = cv2.undistort(roi, mtx, dist, None, mtx)\n",
    "roi = cv2.warpPerspective(roi, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "print(\"This is how the mask looks like on the birdview image\")\n",
    "plt.imshow(roi,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how the mask looks like on the original image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e7550f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADfCAYAAAD4Bhh5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGfSSNHAGvSQNnEEvSQNn0EvSwP0/7x+//yE6FCYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d594ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cv2.warpPerspective(roi, np.linalg.inv(M), (1280,720), flags=cv2.INTER_LINEAR)\n",
    "print(\"This is how the mask looks like on the original image\")\n",
    "plt.imshow(test,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filters import topo_parabolic_bump_filter, abs_sobel_thresh, sob_filter, bump_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane and LaneFinder\n",
    "available in Lane.py and LaneFinder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_vertices = [[300,420],[200,670],[700,600],[1150,670],[1000,420]]\n",
    "anchor_points = [[592, 453], [695,453],[970, 630],[348, 630]]\n",
    "tranformed_image_size = (720,720)\n",
    "PIX2XM = 3.7/330 #lane width is 3.7 meters, 430 pixels in image\n",
    "PIX2YM = 3.0/60 #dash line is 3 meters long, 60 pixels in image\n",
    "from LaneFinder import LaneFinder\n",
    "############\n",
    "import cv2\n",
    "import numpy as np\n",
    "from Lane import Lane\n",
    "\n",
    "class LaneFinder:\n",
    "    def __init__(self, original_image_size, mask_vertices, anchor_points, tranformed_image_size,\n",
    "                 cali_mtx, cali_dist, convert_x, convert_y,\n",
    "                 window_width=80, window_height=80, margin=100,\n",
    "                 left_lane_bound=None, right_lane_bound=None,\n",
    "                 left_lane_pixel_thres = 600, right_lane_pixel_thres=200,\n",
    "                 smooth_window=5):\n",
    "        self.original_image_size = original_image_size\n",
    "        self.lane = Lane(tranformed_image_size, convert_x, convert_y, smooth_window)\n",
    "        self.height = tranformed_image_size[0]\n",
    "        self.width = tranformed_image_size[1]\n",
    "        self.window_width = window_width\n",
    "        self.window_height = window_height\n",
    "        self.margin = margin\n",
    "        self.level_num = (int)(tranformed_image_size[0]/window_height)\n",
    "        self.window = np.ones(window_width) # Define window template\n",
    "        self.channels = []\n",
    "        [self.idx,self.idy] = np.meshgrid(range(tranformed_image_size[1]),\n",
    "                                          range(tranformed_image_size[0]))\n",
    "        self.calibration_matrix = cali_mtx\n",
    "        self.calibration_dist = cali_dist\n",
    "\n",
    "        self.poly_c0 = np.array([np.nan]*smooth_window)\n",
    "        self.poly_c1 = np.array([np.nan]*smooth_window)\n",
    "        self.poly_c2 = np.array([np.nan]*smooth_window)\n",
    "\n",
    "        src = np.array(anchor_points, dtype = \"float32\")\n",
    "        h_margin = 200\n",
    "        top_margin = 200\n",
    "        bottom_margin = 50\n",
    "        dst = np.array([[h_margin, top_margin],\n",
    "                        [tranformed_image_size[0] - h_margin, top_margin],\n",
    "                        [tranformed_image_size[0] - h_margin, tranformed_image_size[1] - bottom_margin],\n",
    "                        [h_margin, tranformed_image_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.M_inv = np.linalg.inv(self.M)\n",
    "\n",
    "        roi = np.zeros(original_image_size,dtype=np.uint8)\n",
    "        cv2.fillPoly(roi, np.array([mask_vertices], dtype=np.int32),1)\n",
    "        roi = cv2.undistort(roi, cali_mtx, cali_dist, None, cali_mtx)\n",
    "        self.mask = cv2.warpPerspective(roi, self.M, tranformed_image_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # set left lane and right lane researching region individually\n",
    "        if left_lane_bound is None:\n",
    "            left_lane_bound = (int(self.width/8),int(self.width*3/8),int(self.height*3/4), self.height)\n",
    "        if right_lane_bound is None:\n",
    "            right_lane_bound = (int(self.width*5/8),int(self.width*7/8),int(self.height*1/8), self.height)\n",
    "        self.lane_bound = [left_lane_bound, right_lane_bound]\n",
    "\n",
    "        self.left_lane_pixel_thres = left_lane_pixel_thres\n",
    "        self.right_lane_pixel_thres = right_lane_pixel_thres\n",
    "        self.texts = [] # store center offset and curvature, as well as other info for debuging\n",
    "\n",
    "    def window_mask(self, center, level):\n",
    "        output = np.zeros((self.height,self.width))\n",
    "        output[int(self.height-(level+1)*self.window_height):int(self.height-level*self.window_height),\n",
    "               max(0,int(center-self.window_width/2)):min(int(center+self.window_width/2),self.width)] = 1\n",
    "        return output\n",
    "\n",
    "    def initial_window_finder(self, image, threshold,\n",
    "                              left_bound, right_bound,\n",
    "                              upper_bound, lower_bound):\n",
    "        # Sum the bottom of the image with the given height vertically to get a 1d array\n",
    "        # Each element in this array counts number of white pixels in that column\n",
    "        v_sum = np.sum(image[upper_bound:lower_bound,left_bound:right_bound], axis=0)\n",
    "        # Convolve the vertical image slice with the window template\n",
    "        conv = np.convolve(self.window,v_sum)\n",
    "        # the peak should have enough signals, and should stand out from the rests (not noise).\n",
    "        if conv.max()>threshold:\n",
    "            center = int(np.argmax(conv)-self.window.size/2 + left_bound)\n",
    "            return center\n",
    "        else:\n",
    "            print(\"No enough pixels detected\")\n",
    "\n",
    "        return -1\n",
    "\n",
    "    def channel_decompose(self, img, saturation_white_thresh=(0, 2),\n",
    "                         saturation_yellow_thresh=(100, 180),\n",
    "                         hue_thresh=(18, 25), value_thresh=(200, 255),\n",
    "                         component_limit=6, min_area=1000,\n",
    "                         ksize=15):\n",
    "\n",
    "\n",
    "        # Convert to HLS color space and separate the V channel\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "        h_channel = hsv[:,:,0]\n",
    "        s_channel = hsv[:,:,1]\n",
    "        v_channel = hsv[:,:,2]\n",
    "\n",
    "        v_binary = np.zeros_like(v_channel)\n",
    "        v_binary[(v_channel>=value_thresh[0])&(v_channel<=value_thresh[1])] = 1\n",
    "        #\n",
    "        # r_channel = img[:,:,0]\n",
    "        # r_binary = topo_parabolic_bump_filter(cv2.GaussianBlur(r_channel,(5,5),0),\n",
    "        #                                       x_thresh=(0.9,1), min_area=1000, ksize=ksize)\n",
    "        #\n",
    "        # h_binary = np.zeros_like(h_channel)\n",
    "        # h_binary[(h_channel>=hue_thresh[0])&(h_channel<=hue_thresh[1])] = 1\n",
    "        #\n",
    "        # sw_binary = np.zeros_like(s_channel)\n",
    "        # sw_binary[(s_channel>=saturation_white_thresh[0])&(s_channel<=saturation_white_thresh[1])] = 1\n",
    "        # sy_binary = np.zeros_like(s_channel)\n",
    "        # sy_binary[(s_channel>=saturation_yellow_thresh[0])&(s_channel<=saturation_yellow_thresh[1])] = 1\n",
    "\n",
    "        self.thresholds = [50]\n",
    "\n",
    "        return [v_binary]\n",
    "\n",
    "#         return [v_binary, r_binary,h_binary,sw_binary,sy_binary]\n",
    "#         return [v_channel*v_binary, r_channel*r_binary,h_channel*h_binary,\n",
    "#                 s_channel*sw_binary,s_channel*sy_binary]\n",
    "\n",
    "    def prepare_channels(self, img):\n",
    "        channels = self.channel_decompose(img)\n",
    "        self.channels = [im*self.mask for im in channels] #ignore outside of masked region\n",
    "        return len(channels)\n",
    "\n",
    "    def find_window_per_level(self, image, center, level, threshold):\n",
    "        # Find the best centroid by using past center as a reference\n",
    "        min_index = max(center-self.margin, 0)\n",
    "        max_index = min(center+self.margin, self.width)\n",
    "        v_projection = np.sum(image[int(self.height-(level+1)*self.window_height):\n",
    "                                    int(self.height-level*self.window_height),\n",
    "                                    min_index:max_index],\n",
    "                              axis=0)\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        conv_signal = np.convolve(self.window, v_projection)\n",
    "        peak_idx = np.argmax(conv_signal)\n",
    "        # Update window center only if pixels in that slot exceed our threshold\n",
    "        if (conv_signal[peak_idx]>threshold):\n",
    "            # Use window_width/2 as offset because convolution signal reference is at right side of window,\n",
    "            # not center of window\n",
    "            center = peak_idx+min_index-int(self.window_width/2)\n",
    "        return center\n",
    "\n",
    "    def get_points_in_window(self, image, level, window_center):\n",
    "        points = np.zeros_like(image)\n",
    "        if window_center>=0:\n",
    "            window_mask = self.window_mask(window_center,level)\n",
    "            points = image*window_mask\n",
    "        return points\n",
    "\n",
    "    def init_lane_finder(self, side):\n",
    "        idx = -1\n",
    "        center = -1\n",
    "        # search window center starting from the first channel\n",
    "        # for the current channel, locate the bin with most pixels within the given bound\n",
    "        # bounds are different for left lane and right, and are defined in the initializer.\n",
    "        while center<0 and idx<len(self.channels)-1:\n",
    "            idx += 1 # move to the next channel if cannot find a window with peak in this channel\n",
    "            center = self.initial_window_finder(self.channels[idx],self.thresholds[idx],\n",
    "                                                self.lane_bound[side][0], self.lane_bound[side][1],\n",
    "                                                self.lane_bound[side][2], self.lane_bound[side][3])\n",
    "\n",
    "        self.window_centroids[side].append((idx, center))\n",
    "        points = np.zeros((self.height, self.width))\n",
    "        if center>=0:\n",
    "            # when a window with peak is found\n",
    "            # slice the birdview image into several layers and search for peak in each layer.\n",
    "            points = self.get_points_in_window(self.channels[idx], 0, center)\n",
    "            for level in range(1,self.level_num):\n",
    "                center = self.find_window_per_level(self.channels[idx], center,\n",
    "                                                    level, self.thresholds[idx])\n",
    "                level_points = self.get_points_in_window(self.channels[idx], level, center)\n",
    "                points = np.maximum(points,level_points)\n",
    "                self.window_centroids[side].append((idx, center))\n",
    "        else:\n",
    "            print(\"Could not find a peak window to start with in all channels\")\n",
    "        if side==0:\n",
    "            (self.lane.left_y, self.lane.left_x) = np.where(points>0)\n",
    "            print(self.lane.left_x.size)\n",
    "            self.lane.polyfit_left()\n",
    "        else:\n",
    "            (self.lane.right_y, self.lane.right_x) = np.where(points>0)\n",
    "            self.lane.polyfit_right()\n",
    "\n",
    "    def tube_lane_finder(self, img, side):\n",
    "        tube_mask = np.zeros_like(img)\n",
    "        if side==0: # left lane\n",
    "            search_radius = 10\n",
    "            while (search_radius<self.margin and\n",
    "                   self.lane.left_x.size<self.left_lane_pixel_thres):\n",
    "                tube_mask[np.abs(self.idx-np.repeat([self.lane.left_fitx],\n",
    "                                           self.width,axis=0).T)<search_radius]=1\n",
    "                l_points = img*tube_mask\n",
    "                (self.lane.left_y, self.lane.left_x) = np.where(l_points>0)\n",
    "                search_radius += 10\n",
    "\n",
    "            return self.lane.polyfit_left()\n",
    "\n",
    "        else:  # right lane\n",
    "            search_radius = 10\n",
    "            while (search_radius<self.margin and\n",
    "                   self.lane.right_x.size<self.right_lane_pixel_thres):\n",
    "                tube_mask[np.abs(self.idx-np.repeat([self.lane.right_fitx],\n",
    "                                               self.width,axis=0).T)<search_radius]=1\n",
    "                r_points = img*tube_mask\n",
    "                (self.lane.right_y, self.lane.right_x) = np.where(r_points>0)\n",
    "                search_radius += 10\n",
    "\n",
    "            return self.lane.polyfit_right()\n",
    "\n",
    "    def draw_lane(self):\n",
    "        # Draw the lane pixels and lane curve\n",
    "        left_bound_idx, right_bound_idx = None, None\n",
    "        if self.lane.left_x.size>0:\n",
    "            # Make left lane pixels blue\n",
    "            self.lane.canvas[self.lane.left_y,self.lane.left_x,2] = 255\n",
    "        if self.lane.left_detected:\n",
    "            # Draw polynomial\n",
    "            self.lane.canvas[self.lane.ploty,self.lane.left_fitx,0:2] = 155\n",
    "            left_bound_idx = np.repeat([self.lane.left_fitx],\n",
    "                                        self.width,axis=0).T\n",
    "        if self.lane.right_x.size>0:\n",
    "            #right lane pixels red,\n",
    "            self.lane.canvas[self.lane.right_y,self.lane.right_x,0] = 255\n",
    "        if self.lane.right_detected:\n",
    "            self.lane.canvas[self.lane.ploty,self.lane.right_fitx,0:2] = 155\n",
    "#             self.lane.canvas[self.lane.ploty,self.lane.right_fitx,2] = 155\n",
    "            right_bound_idx = np.repeat([self.lane.right_fitx], self.width,axis=0).T\n",
    "        elif left_bound_idx is not None:\n",
    "            right_bound_idx = left_bound_idx + self.lane.width\n",
    "\n",
    "#         if (left_bound_idx is not None) and (right_bound_idx is not None):\n",
    "#             self.lane.canvas[(self.idx-left_bound_idx>0)&(self.idx-right_bound_idx<0),1] = 50\n",
    "        return self.lane.canvas\n",
    "\n",
    "    def draw_windows(self):\n",
    "        canvas = np.zeros((self.height,self.width))\n",
    "        for side in [0,1]:\n",
    "            level = -1\n",
    "            for _, window_center in self.window_centroids[side]:\n",
    "                level += 1\n",
    "                canvas = np.maximum(canvas, self.window_mask(window_center,level))\n",
    "        return canvas\n",
    "    \n",
    "    def draw_result(self, original_img):\n",
    "        new_img = np.copy(original_img)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        text_v_position = 70\n",
    "        for text in self.texts:\n",
    "            cv2.putText(new_img, text, (40, text_v_position),\n",
    "                        font, 1.0, (200,255,155), 2, cv2.LINE_AA)\n",
    "            text_v_position += 30\n",
    "\n",
    "        return new_img\n",
    "\n",
    "    def pipeline(self, img):\n",
    "        # reset information for the current frame\n",
    "        self.lane.reset_canvas()\n",
    "        self.texts = []\n",
    "        self.window_centroids = [[],[]]\n",
    "\n",
    "        # undistort and apply perspective transformation to get birdview\n",
    "        warped_img = cv2.undistort(img, self.calibration_matrix, self.calibration_dist,\n",
    "                                   None, self.calibration_matrix)\n",
    "        warped_img = cv2.warpPerspective(warped_img, self.M,\n",
    "                                         (self.height,self.width),\n",
    "                                         flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # apply different filters to create candidate channels\n",
    "        L = self.prepare_channels(warped_img)\n",
    "#         return np.dstack((self.channels[0],self.channels[0],self.channels[0]))\n",
    "\n",
    "        text = ''\n",
    "        # If lane-line is detected from the previous frame,\n",
    "        # then use tube_lane_finder\n",
    "        if self.lane.left_detected and self.lane.left_fitx is not None:\n",
    "            channel_left_idx = 0\n",
    "            while channel_left_idx<L and (not self.tube_lane_finder(self.channels[channel_left_idx],0)):\n",
    "                channel_left_idx += 1\n",
    "            text += 'L channel:' + str(channel_left_idx)+' pix:'+ str(self.lane.left_x.size) + ', '\n",
    "        else: # otherwise search from scratch\n",
    "            text += 'L init '\n",
    "            self.init_lane_finder(side=0)\n",
    "\n",
    "        # same process applied to right lane-line\n",
    "        if self.lane.right_detected and self.lane.right_fitx is not None:\n",
    "            channel_right_idx = 0\n",
    "            while channel_right_idx<L and (not self.tube_lane_finder(self.channels[channel_right_idx],1)):\n",
    "                channel_right_idx += 1\n",
    "            text += 'R channel:' + str(channel_right_idx)+' pix:'+ str(self.lane.right_x.size)\n",
    "        else:\n",
    "            text += 'R init '\n",
    "            self.init_lane_finder(side=1)\n",
    "\n",
    "        if len(text)>0: self.texts.append(text)\n",
    "\n",
    "        if (self.lane.left_x.size>0) and (self.lane.right_x.size>0):\n",
    "            # compute curvature and center offset\n",
    "            (curvature, center_offset) = self.lane.analyze()\n",
    "            self.texts.append(\"Curvature: \"+\"{:04.1f}\".format(curvature) + 'm')\n",
    "            self.texts.append(\"Distance from Center: \"+\"{:04.3f}\".format(center_offset)+ 'm')\n",
    "\n",
    "        return self.draw_lane()\n",
    "        \n",
    "        overlay = cv2.warpPerspective(self.draw_lane(), self.M_inv,\n",
    "                                      (self.original_image_size[1],self.original_image_size[0]),\n",
    "                                      flags=cv2.INTER_LINEAR)\n",
    "        return self.draw_result(cv2.addWeighted(img, 1, overlay, 1, 0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "14954\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e16a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = cv2.imread(\"test_images/test6.jpg\")\n",
    "print(test_img.shape)\n",
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=80, window_height=80, margin=100)\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "res = lane_finder.pipeline(test_img)\n",
    "plt.imshow(res)\n",
    "mpimg.imsave(\"test6_out0.png\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([284, 273, 273, 273, 273, 273, 273, 255, 255, 255, 255, 255, 255,\n",
       "       239, 239, 239, 239, 239, 239, 226, 226, 226])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_finder.lane.left_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 189),\n",
       "  (0, 266),\n",
       "  (0, 279),\n",
       "  (0, 295),\n",
       "  (0, 313),\n",
       "  (0, 324),\n",
       "  (0, 324),\n",
       "  (0, 324),\n",
       "  (0, 324)],\n",
       " [(0, 554),\n",
       "  (0, 579),\n",
       "  (0, 592),\n",
       "  (0, 599),\n",
       "  (0, 599),\n",
       "  (0, 634),\n",
       "  (0, 634),\n",
       "  (0, 675),\n",
       "  (0, 675)]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_finder.window_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'project_video.mp4'\n",
    "output = input_vid[:-4]+\"_output.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'challenge_video.mp4'\n",
    "output = input_vid[:-4]+\"_overlay_polyfinder_curvature.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'harder_challenge_video.mp4'\n",
    "output = input_vid[:-4]+\"_overlay_polyfinder_curvature.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "clip = (VideoFileClip(\"project_video_channels/project_video_channel_0.mp4\")\n",
    "        .resize(0.2))\n",
    "clip.speedx(3).write_gif(\"channel0.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip('myanimation.gif') # can be gif or movie\n",
    "for frame in clip.iter_frames():\n",
    "    mpimg.imsave(\"channel0.png\",frame)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import heapq\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_imgs = [\"camera_cal/calibration\"+str(i)+\".jpg\" for i in range(1,21)]\n",
    "grid_sizes = [(9,5),(9,6),(9,6),(6,5),(7,6)]+ [(9,6)]*15\n",
    "\n",
    "def calibration_matrix(imgs, grid_sizes):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    for idx, fname in enumerate(imgs):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        grid_size = grid_sizes[idx]\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, grid_size, None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objp = np.zeros((grid_size[0]*grid_size[1],3), np.float32)\n",
    "            objp[:,:2] = np.mgrid[0:grid_size[0], 0:grid_size[1]].T.reshape(-1,2)\n",
    "\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and display the corners\n",
    "#             cv2.drawChessboardCorners(img, grid_size, corners, ret)\n",
    "#             write_name = 'camera_cal/corners_found'+str(idx+1)+'.jpg'\n",
    "#             cv2.imwrite(write_name, img)\n",
    "    #         cv2.imshow('img', img)\n",
    "    #         cv2.waitKey(500)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (mtx,dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx, dist = calibration_matrix(check_imgs,grid_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (720,720)\n",
    "\n",
    "def perspective_transformation(target_img_size):\n",
    "    src = np.array([[592, 453], \n",
    "                    [695,453],\n",
    "                    [970, 630],\n",
    "                    [348, 630]], dtype = \"float32\")\n",
    "\n",
    "    h_margin = 200\n",
    "    top_margin = 200\n",
    "    bottom_margin = 50\n",
    "    dst = np.array([[h_margin, top_margin], \n",
    "                    [target_img_size[0] - h_margin, top_margin],\n",
    "                    [target_img_size[0] - h_margin, target_img_size[1] - bottom_margin],\n",
    "                    [h_margin, target_img_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "    return cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "M = perspective_transformation(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topo_parabolic_bump_filter(img, x_thresh=(0.5,1), \n",
    "                               y_thresh=(0,0.0001), \n",
    "                               min_area=400, ksize=3):\n",
    "    kernel = np.array([[-1]*ksize+[2]*ksize+[-1]*ksize])\n",
    "    res = np.abs(cv2.filter2D(img, -1, kernel))\n",
    "    res = res/np.max(res)\n",
    "    y_kernel = np.array([[-1],[-1],[0],[1],[1]])\n",
    "    mask = np.abs(cv2.filter2D(img, -1, y_kernel))\n",
    "    binary = np.zeros_like(res)\n",
    "    binary[(res>=x_thresh[0])&(res<=x_thresh[1])&(mask<y_thresh[1])] = 1\n",
    "    d_kernel = np.ones((3,3),np.uint8)\n",
    "    binary = cv2.dilate(binary,d_kernel,iterations = 1)\n",
    "    binary = cv2.erode(binary,d_kernel,iterations = 1)\n",
    "    \n",
    "    n,n_blobs,stats,cent = cv2.connectedComponentsWithStats(binary.astype(np.uint8),\n",
    "                                                            connectivity=8,ltype=cv2.CV_32S)\n",
    "    tot = img.shape[0]*img.shape[1]\n",
    "    areas = stats[:,-1]\n",
    "    big_segs = heapq.nlargest(6, range(len(areas)), areas.take)\n",
    "    binary = np.zeros_like(res)\n",
    "    for i in big_segs[1:]:\n",
    "        if areas[i]>min_area: binary[n_blobs==i]=1\n",
    "    return binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12023ef28>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUm4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119f03438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def region_of_interest(shape, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros(shape,dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, np.array([vertices], dtype=np.int32),1)\n",
    "    return mask\n",
    "roi = region_of_interest((720,1280), [[300,420],[200,670],[700,600],[1150,670],[1000,420]])\n",
    "roi = cv2.undistort(roi, mtx, dist, None, mtx)\n",
    "roi = cv2.warpPerspective(roi, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "plt.imshow(roi,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lane():\n",
    "    def __init__(self, img_size, threshold):\n",
    "        self.img_size = img_size\n",
    "        self.threshold = threshold # threshold for polynomial fitting.\n",
    "        # y coodinates, will be used to plot polynomial\n",
    "        self.ploty = np.linspace(0, img_size[0]-1, img_size[0]).astype('int64')\n",
    "        # was the edges of the lane detected in the last iteration?\n",
    "        self.left_detected = False\n",
    "        self.right_detected = False\n",
    "        self.left_x = None\n",
    "        self.left_y = None\n",
    "        self.right_x = None\n",
    "        self.right_y = None\n",
    "        self.left_poly = None\n",
    "        self.right_poly = None\n",
    "        self.last_left_fitx = None\n",
    "        self.last_right_fitx = None\n",
    "        self.left_fitx = None\n",
    "        self.right_fitx = None\n",
    "        \n",
    "    def polyfit_left(self):\n",
    "        self.last_left_fitx = self.left_fitx\n",
    "        self.left_poly = None\n",
    "        self.left_fitx = None\n",
    "        if self.left_x is not None:\n",
    "            # Fit a second order polynomial\n",
    "            left_poly, err, _, _, _ = np.polyfit(self.left_y, self.left_x, 2, full=True)\n",
    "            print(err)\n",
    "            if err<self.threshold:\n",
    "                self.left_poly = left_poly\n",
    "                self.left_fitx = (self.left_poly[0]*self.ploty**2 + \n",
    "                                  self.left_poly[1]*self.ploty + \n",
    "                                  self.left_poly[2]).astype('int64')\n",
    "                self.left_fitx[self.left_fitx<0]=0\n",
    "                self.left_fitx[self.left_fitx>img_size[0]-1]=img_size[0]-1\n",
    "                \n",
    "        return self.left_fitx\n",
    "            \n",
    "    def polyfit_right(self):\n",
    "        self.last_right_fitx = self.right_fitx\n",
    "        self.right_poly = None\n",
    "        self.right_fitx = None\n",
    "        if self.right_x is not None:\n",
    "            # Fit a second order polynomial\n",
    "            right_poly, err, _, _, _ = np.polyfit(self.right_y, self.right_x, 2, full=True)\n",
    "            print(err)\n",
    "            if err<self.threshold:\n",
    "                self.right_poly = np.polyfit(self.right_y, self.right_x, 2)\n",
    "                self.right_fitx = (self.right_poly[0]*self.ploty**2 + \n",
    "                                   self.right_poly[1]*self.ploty + \n",
    "                                   self.right_poly[2]).astype('int64')\n",
    "                self.right_fitx[self.right_fitx<0]=0\n",
    "                self.right_fitx[self.right_fitx>img_size[0]-1]=img_size[0]-1\n",
    "            \n",
    "        return self.right_fitx\n",
    "\n",
    "lane = Lane(img_size, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),\n",
    "           max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def initial_window_finder(image, window, threshold,\n",
    "                          left_bound, right_bound, \n",
    "                          upper_bound, lower_bound):\n",
    "    # Find the starting position for a lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template\n",
    "    \n",
    "    # Sum the bottom of the image with the given height to get slice\n",
    "    v_sum = np.sum(image[upper_bound:lower_bound,left_bound:right_bound], axis=0)\n",
    "    conv = np.convolve(window,v_sum)\n",
    "    center = -1\n",
    "    if conv.max()>threshold:\n",
    "        center = int(np.argmax(conv)-window.size/2 + left_bound)\n",
    "\n",
    "    return center\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin, threshold, mask):\n",
    "    image = image*mask #ignore outside of masked region\n",
    "    window = np.ones(window_width) # Define window template\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    level_num = (int)(image.shape[0]/window_height)\n",
    "    \n",
    "    upper_bound = (int)(image.shape[0]*3/4)\n",
    "    l_center,r_center = (-1,-1) # Default window center to be -1. This means not existing.\n",
    "    # Keep searching until we find \n",
    "    while l_center<0 and upper_bound>=0:\n",
    "        l_center = initial_window_finder(image,window,threshold,\n",
    "                                         int(image.shape[1]/8),int(image.shape[1]*3/8), \n",
    "                                         upper_bound, image.shape[0])\n",
    "        upper_bound -=50\n",
    "        \n",
    "    upper_bound = (int)(image.shape[0]*3/4)\n",
    "    while r_center<0 and upper_bound>=0:    \n",
    "        r_center = initial_window_finder(image,window,threshold,\n",
    "                                         int(image.shape[1]*5/8), int(image.shape[1]*7/8), \n",
    "                                         upper_bound, image.shape[0])\n",
    "        upper_bound -=50\n",
    "        \n",
    "    # If nothing was found, return empty list \n",
    "    if l_center<0 and r_center<0:\n",
    "        return window_centroids\n",
    "    # Otherwise add what ever we found\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(image.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(image[int(image.shape[0]-(level+1)*window_height):int(image.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,image.shape[1]))\n",
    "        l_conv = conv_signal[l_min_index:l_max_index]\n",
    "        # Update window center only if pixels in that slot exceed our threshold\n",
    "        if l_conv.max()>threshold:\n",
    "            l_center = np.argmax(l_conv)+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,image.shape[1]))\n",
    "        r_conv = conv_signal[r_min_index:r_max_index]\n",
    "        if r_conv.max()>threshold:\n",
    "            r_center = np.argmax(r_conv)+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "def laneFinder(binary_warped, lane, window_width = 50, window_height = 80, \n",
    "               margin = 100, threshold=5, mask=None):\n",
    " \n",
    "    if mask is None: mask = np.ones_like(binary_warped)\n",
    "    window_centroids = find_window_centroids(binary_warped, window_width, window_height, \n",
    "                                             margin, threshold, mask)\n",
    "\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(binary_warped)\n",
    "        r_points = np.zeros_like(binary_warped)\n",
    "\n",
    "        # Go through each level and draw the windows\n",
    "        window_boxes = np.zeros_like(binary_warped)\n",
    "        for level, (l_center, r_center) in enumerate(window_centroids):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            if l_center>=0:\n",
    "                l_mask = window_mask(window_width,window_height,binary_warped,l_center,level)\n",
    "                cv2.rectangle(window_boxes, \n",
    "                              (max(0,int(l_center-window_width/2)),\n",
    "                               int(binary_warped.shape[0]-(level+1)*window_height)),\n",
    "                              (min(int(l_center+window_width/2),binary_warped.shape[1]),\n",
    "                               int(binary_warped.shape[0]-level*window_height))\n",
    "                              ,1,3)\n",
    "                l_points = l_points+binary_warped*l_mask\n",
    "            if r_center>=0:\n",
    "                r_mask = window_mask(window_width,window_height,binary_warped,r_center,level)\n",
    "                cv2.rectangle(window_boxes,\n",
    "                              (max(0,int(r_center-window_width/2)),\n",
    "                               int(binary_warped.shape[0]-(level+1)*window_height)),\n",
    "                              (min(int(r_center+window_width/2),binary_warped.shape[1]),\n",
    "                               int(binary_warped.shape[0]-level*window_height))\n",
    "                              ,1,3)\n",
    "                r_points = r_points+binary_warped*r_mask\n",
    "\n",
    "        if l_points.max()>0:\n",
    "            l_points[l_points>1] = 1\n",
    "            lane.left_detected = True\n",
    "            (lane.left_y, lane.left_x) = np.where(l_points>0)\n",
    "        else:\n",
    "            lane.left_detected = True\n",
    "            (lane.left_y, lane.left_x) = (None, None)\n",
    "            \n",
    "        if r_points.max()>0:\n",
    "            r_points[r_points>1] = 1\n",
    "            lane.right_detected = True\n",
    "            (lane.right_y, lane.right_x) = np.where(r_points>0)\n",
    "        else:\n",
    "            lane.right_detected = True\n",
    "            (lane.right_y, lane.right_x) = (None, None)\n",
    "            \n",
    "        left_fitx = lane.polyfit_left()\n",
    "        right_fitx = lane.polyfit_right()\n",
    "        # Draw the results\n",
    "        template = np.array(cv2.merge((l_points,r_points,window_boxes))*255,np.uint8) # make right lane pixels green, left lane red\n",
    "        warpage= np.dstack((binary_warped, binary_warped, binary_warped))*255 # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage.astype(np.uint8), 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "        # Draw polynomial\n",
    "        output[lane.ploty,left_fitx,0:2] = 255\n",
    "        output[lane.ploty,right_fitx,0:2] = 255\n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        print(\"nothing found\")\n",
    "        output = np.array(cv2.merge((binary_warped,binary_warped,binary_warped)),np.uint8)\n",
    "        \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img, lane, mtx, dist, saturation_white_thresh=(0, 2), \n",
    "             saturation_yellow_thresh=(100, 180), \n",
    "             hue_thresh=(18, 25), value_thresh=(220, 255),\n",
    "             component_limit=6, min_area=1000,\n",
    "             ksize=15, mask=None):\n",
    "    \n",
    "    r_channel = img[:,:,0]\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    s_channel = hsv[:,:,1]\n",
    "    v_channel = hsv[:,:,2]\n",
    "    \n",
    "    r_binary = topo_parabolic_bump_filter(cv2.GaussianBlur(r_channel,(5,5),0),\n",
    "                                          x_thresh=(0.9,1), min_area=1000, ksize=ksize)\n",
    "\n",
    "    sw_binary = np.zeros_like(s_channel)\n",
    "    sw_binary[(s_channel>=saturation_white_thresh[0])&(s_channel<=saturation_white_thresh[1])] = 1\n",
    "    sy_binary = np.zeros_like(s_channel)\n",
    "    sy_binary[(s_channel>=saturation_yellow_thresh[0])&(s_channel<=saturation_yellow_thresh[1])] = 1\n",
    "    \n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel>=value_thresh[0])&(v_channel<=value_thresh[1])] = 1\n",
    "    \n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel>=hue_thresh[0])&(h_channel<=hue_thresh[1])] = 1\n",
    "    \n",
    "    perspective = cv2.warpPerspective((v_binary+h_binary+sw_binary+sy_binary)/4, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "#     perspective = cv2.warpPerspective(v_binary, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    if mask is None: mask = np.ones_like(perspective)\n",
    "    res = laneFinder(perspective, lane, window_width = 50, window_height = 80, margin = 100, mask=mask)\n",
    "\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11fa93cc0>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e2b1eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = cv2.imread(\"test_images/straight_lines1.jpg\")\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "res = pipeline(test_img, lane, mtx, dist, mask=roi)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_poly_pipeline_output.mp4\n",
      "[MoviePy] Writing video challenge_video_poly_pipeline_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [01:28<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_poly_pipeline_output.mp4 \n",
      "\n",
      "CPU times: user 1min 22s, sys: 17.8 s, total: 1min 40s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'challenge_video_poly_pipeline_output.mp4'\n",
    "processor = lambda x:pipeline(x, lane, mtx, dist)\n",
    "\n",
    "clip2 = VideoFileClip('challenge_video.mp4')\n",
    "challenge_clip = clip2.fl_image(processor)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_green.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer Perspective Tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (800,1280)\n",
    "\n",
    "def perspective_transformation(target_img_size):\n",
    "    src = np.array([[592, 453], \n",
    "                    [695,453],\n",
    "                    [970, 630],\n",
    "                    [348, 630]], dtype = \"float32\")\n",
    "\n",
    "    h_margin = 200\n",
    "    top_margin = 300\n",
    "    bottom_margin = 50\n",
    "    dst = np.array([[h_margin, top_margin], \n",
    "                    [target_img_size[0] - h_margin, top_margin],\n",
    "                    [target_img_size[0] - h_margin, target_img_size[1] - bottom_margin],\n",
    "                    [h_margin, target_img_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "    return cv2.getPerspectiveTransform(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        sb = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sb = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sb = np.absolute(sb)\n",
    "    sc_sb = np.uint8(abs_sb*255/np.max(abs_sb))\n",
    "    binary_output = np.zeros_like(sc_sb)\n",
    "    binary_output[(sc_sb>thresh_min)&(sc_sb<thresh_max)]=1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lane(original_img, binary_img, l_fit, r_fit, Minv):\n",
    "    new_img = np.copy(original_img)\n",
    "    if l_fit is None or r_fit is None:\n",
    "        return original_img\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    h,w = binary_img.shape\n",
    "    ploty = np.linspace(0, h-1, num=h)# to cover same y-range as image\n",
    "    left_fitx = l_fit[0]*ploty**2 + l_fit[1]*ploty + l_fit[2]\n",
    "    right_fitx = r_fit[0]*ploty**2 + r_fit[1]*ploty + r_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(255,0,255), thickness=15)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(0,255,255), thickness=15)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (w, h)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(new_img, 1, newwarp, 0.5, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_result(original_img, radius, center_dist):\n",
    "    new_img = np.copy(original_img)\n",
    "    h = new_img.shape[0]\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    text = 'Curve radius: ' + '{:04.2f}'.format(radius) + 'm'\n",
    "    cv2.putText(new_img, text, (40,70), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    direction = ''\n",
    "    if center_dist > 0:\n",
    "        direction = 'right'\n",
    "    elif center_dist < 0:\n",
    "        direction = 'left'\n",
    "    abs_center_dist = abs(center_dist)\n",
    "    text = '{:04.3f}'.format(abs_center_dist) + 'm ' + direction + ' of center'\n",
    "    cv2.putText(new_img, text, (40,120), font, 1.5, (200,255,155), 2, cv2.LINE_AA)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exampleImg_out2 = draw_data(exampleImg_out1, (rad_l+rad_r)/2, d_center)\n",
    "plt.imshow(exampleImg_out2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import heapq\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_imgs = [\"camera_cal/calibration\"+str(i)+\".jpg\" for i in range(1,21)]\n",
    "grid_sizes = [(9,5),(9,6),(9,6),(6,5),(7,6)]+ [(9,6)]*15\n",
    "\n",
    "def calibration_matrix(imgs, grid_sizes):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    for idx, fname in enumerate(imgs):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        grid_size = grid_sizes[idx]\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, grid_size, None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objp = np.zeros((grid_size[0]*grid_size[1],3), np.float32)\n",
    "            objp[:,:2] = np.mgrid[0:grid_size[0], 0:grid_size[1]].T.reshape(-1,2)\n",
    "\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (mtx,dist)\n",
    "\n",
    "mtx, dist = calibration_matrix(check_imgs,grid_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation to Birdview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (720,720)\n",
    "\n",
    "def perspective_transformation(target_img_size):\n",
    "    src = np.array([[592, 453], \n",
    "                    [695,453],\n",
    "                    [970, 630],\n",
    "                    [348, 630]], dtype = \"float32\")\n",
    "\n",
    "    h_margin = 200\n",
    "    top_margin = 200\n",
    "    bottom_margin = 30\n",
    "    dst = np.array([[h_margin, top_margin], \n",
    "                    [target_img_size[0] - h_margin, top_margin],\n",
    "                    [target_img_size[0] - h_margin, target_img_size[1] - bottom_margin],\n",
    "                    [h_margin, target_img_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "    return cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "M = perspective_transformation(img_size)\n",
    "M_inv = np.linalg.inv(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how the mask looks like on the birdview image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e4340f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADgxJREFUeJzt3V+MXOV5x/HvE5s/bVJisAFZAddYsQjcYFMrNaKqUtxU\nQCPSCyphRU0UWfINrUCJlNrtRVWpF81NIFErVARJSUVDqBMaZCGIZUBVL+KwDi4EjBNDk2BBsClg\nmkRt5Obpxbxjz7uM2bPemZ05Z78faTRz3jmefd8949++58yZ80RmIkl975l0ByRNF0NBUsVQkFQx\nFCRVDAVJFUNBUmUsoRAR10fEoYg4HBE7xvEzJI1HjPo8hYhYBvwA+ChwBHgK2JqZz4/0B0kai3HM\nFD4MHM7MlzLzl8ADwMfH8HMkjcHyMbzmB4CXB5aPAL/9bv9g1apVuXbt2jF0RVLf/v37X8/MC+da\nbxyhEEPa3rGPEhHbge0Aa9asYWZmZgxdkdQXET9ust44dh+OAJcOLF8CvDJ7pcy8OzM3ZeamCy+c\nM7wkLZJxhMJTwPqIuCwizgZuAR4ew8+RNAYj333IzBMR8afAY8Ay4MuZ+dyof46k8RjHMQUy8xHg\nkXG8tqTx8oxGSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVD\nQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSZU5QyEivhwRRyPi+wNtF0TEnoj4Ybk/v7RHRHyp\nVJt+JiKuHmfnJY1ek5nCPwLXz2rbAezNzPXA3rIMcAOwvty2A3eNppuSFsucoZCZ/wa8Mav548B9\n5fF9wB8NtH81e74DrIiI1aPqrKTxO9NjChdn5qsA5f6i0j6s4vQHzrx7khbbqA80Nqo4Db2q0xEx\nExEzx44dG3E3JJ2pMw2F1/q7BeX+aGlvVHEarDotTaszDYWHgU+Vx58CvjXQ/snyKcRm4Hh/N0NS\nO8xZYDYivgZ8BFgVEUeAvwL+FngwIrYBPwH+uKz+CHAjcBj4BfDpMfRZ0hjNGQqZufU0T20Zsm4C\nty60U5ImxzMaJVUMBUkVQ0FSxVCQVDEUJFUMBUkVQ0FSxVCQVDEUJFUMBUkVQ0FSxVCQVDEUJFUM\nBUkVQ0FSxVCQVDEUJFUMBUkVQ0FSxVCQVDEUJFUMBUmVJqXoL42IJyLiYEQ8FxG3lXbL0Usd1GSm\ncAL4bGZeAWwGbo2IK7EcvdRJTUrRv5qZ3yuP/xs4SK+StOXopQ6a1zGFiFgLbAT2scBy9FadlqZT\n41CIiPcB3wBuz8y3323VIW3vKEdv1WlpOjUKhYg4i14g3J+Z3yzNCy5HL2n6NPn0IYB7gYOZ+YWB\npyxHL3XQnFWngWuBPwGejYgDpe0vsBy91ElNStH/O8OPE4Dl6KXO8YxGSRVDQVLFUJBUMRQkVQwF\nSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQk\nVQwFSZUmdR/OjYjvRsR/lKrTf13aL4uIfaXq9Ncj4uzSfk5ZPlyeXzveIUgapSYzhf8FrsvMq4AN\nwPWlyMvngTtK1ek3gW1l/W3Am5n5QeCOsp6klmhSdToz82dl8axyS+A6YFdpn111ul+NehewpVSZ\nktQCTWtJLivVoY4Ce4AXgbcy80RZZbCy9Mmq0+X548DKIa9p1WlpCjUKhcz8v8zcQK9Y7IeBK4at\nVu6tOi212Lw+fcjMt4Angc3Aiojol50brCx9sup0ef79wBuj6Kyk8Wvy6cOFEbGiPP414PeBg8AT\nwM1ltdlVp/vVqG8GHi/1JSW1QJOq06uB+yJiGb0QeTAzd0fE88ADEfE3wNP0ytVT7v8pIg7TmyHc\nMoZ+SxqTJlWnnwE2Dml/id7xhdnt/8OpsvSSWsYzGiVVDAVJFUNBUsVQkFQxFCRVDAVJFUNBUsVQ\nkFQxFCRVDAVJFUNBUsVQkFQxFCRVDAVJFUNBUsVQkFQxFCRVDAVJFUNBUsVQkFQxFCRVGodCKR33\ndETsLstWnZY6aD4zhdvoFYHps+q01EFNC8xeAvwhcE9ZDqw6LXVS05nCncDngF+V5ZVYdVrqpCa1\nJD8GHM3M/YPNQ1a16rTUAU1qSV4L3BQRNwLnAufRmzmsiIjlZTYwrOr0EatOS+0z50whM3dm5iWZ\nuZZesdjHM/MTWHVa6qSFnKfw58BnSnXpldRVp1eW9s8AOxbWRUmLqcnuw0mZ+STwZHls1Wmpgzyj\nUVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwFSRVDQVLFUJBUMRQkVQwF\nSRVDQVLFUJBUMRQkVQwFSRVDQVKlaS3JH0XEsxFxICJmStsFEbGnVJ3eExHnl/aIiC+VqtPPRMTV\n4xyApNGaz0zh9zJzQ2ZuKss7gL2l6vReTtV3uAFYX27bgbtG1VlJ47eQ3YfB6tKzq05/NXu+Q6+8\n3OoF/BxJi6hpKCTw7YjYHxHbS9vFmfkqQLm/qLSfrDpdDFakljTlmlaIujYzX4mIi4A9EfHCu6zb\nqOp0CZftAGvWrGnYDUnj1mimkJmvlPujwEP0ysW91t8tKPdHy+r9qtN9gxWpB1/TUvTSFJozFCLi\nvRHxG/3HwB8A36euLj276vQny6cQm4Hj/d0MSdOvye7DxcBDEdFf/58z89GIeAp4MCK2AT/hVFHZ\nR4AbgcPAL4BPj7zXksZmzlAo1aWvGtL+X8CWIe0J3DqS3kladJ7RKKliKEiqGAqSKoaCpIqhIKli\nKEiqGAqSKoaCpIqhIKliKEiqGAqSKoaCpIqhIKliKEiqGAqSKoaCpIqhIKliKEiqGAqSKoaCpIqh\nIKnStOr0iojYFREvRMTBiLjGqtNSNzWdKXwReDQzP0Tvcu8Hseq01ElNKkSdB/wucC9AZv4yM9/C\nqtNSJzWZKawDjgFfiYinI+KeUj7OqtNSBzUJheXA1cBdmbkR+DmndhWGaVx1OiJmImLm2LFjjTor\nafyahMIR4Ehm7ivLu+iFhFWnpQ6aMxQy86fAyxFxeWnaAjyPVaelTmpSdRrgz4D7I+Js4CV6laTf\ng1Wnpc5pFAqZeQDYNOQpq05LHeMZjZIqhoKkSvRm+xPuREROQz+kLouI/Zk57DBAZWpmChFBxLBT\nHCQtpqkJhT7DQZqsqQuFPoNBGo35/qFtep7CRAwOxGMO0vyc6R/WqZ0pzObMQWpuIf9fpnqmMFt/\noM4apOFG8cezVaHQZzhItVHOpFsZCn2Gg5a6cexWtzoU+gwHLTXjPMbWmgONTXgwUl23GOfxdGKm\nMMhZg7poMf/gdS4U+gwHdcEkZr+dDYU+w0FtNMld4c6HQp/hoDaYhuNiSyYU+gwHTaNpCIO+JRcK\nfRFhMIzAfN7M/r6Hm6ZAgCUcCuAXruYy6jfr6V5vKf7upy0IBi3pUBi01GcOk3yTLrWwmOZAAEOh\n0vXjDdP+Zpxtdn/bvl3a8vtvUmD28og4MHB7OyJu73Ip+i5c/ak/hsFb27V1PG3rb5MKUYcyc0Nm\nbgB+i16Bl4dYAqXop3ljDvtP38b/MAsx7eOfpr7Mx3y/+7AFeDEzf8wSKkU/6f3taX3TT7NJ/r7a\nvo3me0zhFuBr5XFVij4i5ipFX9WTjIjt9GYSrbAYxxva/EaadotxfKIr269xKJQ6kjcBO+dadUjb\nO7ZAZt4N3F1euzVHkBYaDl1547TdKD/x6No2nc/uww3A9zLztbK8oFL0bddkiui0v33ms726uk3n\nEwpbObXrAJaiB+q/EgZA95xum3Z5+zYqGxcRv07vOMG6zDxe2lYCDwJrKKXoM/ON6P22/g64nlKK\nPjNn5nj91uw+SC3WqGzc1NSSnHQfpCWgUShMyxmNPwMOTboTi2wV8PqkO7GIHO/k/WaTlaYlFA41\nSbAuiYiZpTRmx9senbpwq6SFMxQkVaYlFO6edAcmYKmN2fG2xFR8+iBpekzLTEHSlJh4KETE9RFx\nqFx/Ycfc/2L6RcSlEfFERByMiOci4rbS3tlrUABExLKIeDoidpflyyJiXxnv18v3Z4iIc8ry4fL8\n2kn2+0xFxIqI2BURL5RtfU0XtvFEQyEilgF/T+97FVcCWyPiykn2aUROAJ/NzCuAzcCtZVxdvwbF\nbcDBgeXPA3eU8b4JbCvt24A3M/ODwB1lvTb6IvBoZn4IuIre2Nu/jTNzYjfgGuCxgeWdwM5J9mlM\n4/wW8FF6J2itLm2r6Z2fAfAPwNaB9U+u15YbvS++7QWuA3bT+7bs68Dy2dsaeAy4pjxeXtaLSY9h\nnuM9D/jP2f3uwjae9O7D6a690BllarwR2Mesa1AAc12Dok3uBD4H/KosrwTeyswTZXlwTCfHW54/\nXtZvk3XAMeArZZfpnoh4Lx3YxpMOhUbXXmiriHgf8A3g9sx8+91WHdLWmt9DRHwMOJqZ+webh6ya\nDZ5ri+XA1cBdmbkR+DmndhWGac2YJx0Knb32QkScRS8Q7s/Mb5bmrl6D4lrgpoj4EfAAvV2IO+ld\niq9/Kv3gmE6Otzz/fuCNxezwCBwBjmTmvrK8i15ItH4bTzoUngLWl6PUZ9O73NvDE+7TgpWvj98L\nHMzMLww81clrUGTmzsy8JDPX0tuGj2fmJ4AngJvLarPH2/893FzWn8q/mqeTmT8FXo6Iy0vTFuB5\nurCNJ31QA7gR+AHwIvCXk+7PiMb0O/Smhs8AB8rtRnr7zXuBH5b7C8r6Qe9TmBeBZ4FNkx7DAsb+\nEWB3ebwO+C5wGPgX4JzSfm5ZPlyeXzfpfp/hWDcAM2U7/ytwfhe2sWc0SqpMevdB0pQxFCRVDAVJ\nFUNBUsVQkFQxFCRVDAVJFUNBUuX/AT0GwkrjCFqgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d578358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def region_of_interest(shape, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros(shape,dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, np.array([vertices], dtype=np.int32),1)\n",
    "    return mask\n",
    "roi = region_of_interest((720,1280), [[300,420],[200,670],[700,600],[1150,670],[1000,420]])\n",
    "roi = cv2.undistort(roi, mtx, dist, None, mtx)\n",
    "roi = cv2.warpPerspective(roi, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "print(\"This is how the mask looks like on the birdview image\")\n",
    "plt.imshow(roi,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how the mask looks like on the original image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10e7550f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADfCAYAAAD4Bhh5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGfSSNHAGvSQNnEEvSQNn0EvSwP0/7x+//yE6FCYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d594ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = cv2.warpPerspective(roi, np.linalg.inv(M), (1280,720), flags=cv2.INTER_LINEAR)\n",
    "print(\"This is how the mask looks like on the original image\")\n",
    "plt.imshow(test,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Filters import topo_parabolic_bump_filter, abs_sobel_thresh, sob_filter, bump_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane and LaneFinder\n",
    "available in Lane.py and LaneFinder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_vertices = [[300,420],[200,670],[700,600],[1150,670],[1000,420]]\n",
    "anchor_points = [[592, 453], [695,453],[970, 630],[348, 630]]\n",
    "tranformed_image_size = (720,720)\n",
    "PIX2XM = 3.7/330 #lane width is 3.7 meters, 430 pixels in image\n",
    "PIX2YM = 3.0/60 #dash line is 3 meters long, 60 pixels in image\n",
    "from LaneFinder import LaneFinder\n",
    "############\n",
    "import cv2\n",
    "import numpy as np\n",
    "from Lane import Lane\n",
    "\n",
    "class LaneFinder:\n",
    "    def __init__(self, original_image_size, mask_vertices, anchor_points, tranformed_image_size,\n",
    "                 cali_mtx, cali_dist, convert_x, convert_y,\n",
    "                 window_width=50, window_height=80, margin=100,\n",
    "                 left_lane_bound=None, right_lane_bound=None,\n",
    "                 left_lane_pixel_thres = 600, right_lane_pixel_thres=200,\n",
    "                 smooth_window=5):\n",
    "        self.original_image_size = original_image_size\n",
    "        self.lane = Lane(tranformed_image_size, convert_x, convert_y, smooth_window)\n",
    "        self.height = tranformed_image_size[0]\n",
    "        self.width = tranformed_image_size[1]\n",
    "        self.window_width = window_width\n",
    "        self.window_height = window_height\n",
    "        self.margin = margin\n",
    "        self.level_num = (int)(tranformed_image_size[0]/window_height)\n",
    "        self.window = np.ones(window_width) # Define window template\n",
    "        self.channels = []\n",
    "        [self.idx,self.idy] = np.meshgrid(range(tranformed_image_size[1]),\n",
    "                                          range(tranformed_image_size[0]))\n",
    "        self.calibration_matrix = cali_mtx\n",
    "        self.calibration_dist = cali_dist\n",
    "\n",
    "        self.poly_c0 = np.array([np.nan]*smooth_window)\n",
    "        self.poly_c1 = np.array([np.nan]*smooth_window)\n",
    "        self.poly_c2 = np.array([np.nan]*smooth_window)\n",
    "\n",
    "        src = np.array(anchor_points, dtype = \"float32\")\n",
    "        h_margin = 200\n",
    "        top_margin = 200\n",
    "        bottom_margin = 50\n",
    "        dst = np.array([[h_margin, top_margin],\n",
    "                        [tranformed_image_size[0] - h_margin, top_margin],\n",
    "                        [tranformed_image_size[0] - h_margin, tranformed_image_size[1] - bottom_margin],\n",
    "                        [h_margin, tranformed_image_size[1] - bottom_margin]], dtype = \"float32\")\n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        self.M_inv = np.linalg.inv(self.M)\n",
    "\n",
    "        roi = np.zeros(original_image_size,dtype=np.uint8)\n",
    "        cv2.fillPoly(roi, np.array([mask_vertices], dtype=np.int32),1)\n",
    "        roi = cv2.undistort(roi, cali_mtx, cali_dist, None, cali_mtx)\n",
    "        self.mask = cv2.warpPerspective(roi, self.M, tranformed_image_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        if left_lane_bound is None:\n",
    "            left_lane_bound = (int(self.width/8),int(self.width*3/8),int(self.height*3/4), self.height)\n",
    "        if right_lane_bound is None:\n",
    "            right_lane_bound = (int(self.width*5/8),int(self.width*7/8),int(self.height*1/8), self.height)\n",
    "\n",
    "        self.set_lane_initial_detect_range(left_lane_bound, right_lane_bound)\n",
    "\n",
    "        self.left_lane_pixel_thres = left_lane_pixel_thres\n",
    "        self.right_lane_pixel_thres = right_lane_pixel_thres\n",
    "        self.texts = [] # store center offset and curvature, as well as other info for debuging\n",
    "\n",
    "    def set_lane_initial_detect_range(self, left_lane_bound, right_lane_bound):\n",
    "        self.lane_bound = [left_lane_bound, right_lane_bound]\n",
    "\n",
    "    def window_mask(self, center, level):\n",
    "        output = np.zeros((self.height,self.width))\n",
    "        output[int(self.height-(level+1)*self.window_height):int(self.height-level*self.window_height),\n",
    "               max(0,int(center-self.window_width/2)):min(int(center+self.window_width/2),self.width)] = 1\n",
    "        return output\n",
    "\n",
    "    def initial_window_finder(self, image, threshold,\n",
    "                              left_bound, right_bound,\n",
    "                              upper_bound, lower_bound):\n",
    "        # Sum the bottom of the image with the given height vertically to get a 1d array\n",
    "        # Each element in this array counts number of white pixels in that column\n",
    "        v_sum = np.sum(image[upper_bound:lower_bound,left_bound:right_bound], axis=0)\n",
    "        # Convolve the vertical image slice with the window template\n",
    "        conv = np.convolve(self.window,v_sum)\n",
    "        # the peak should have enough signals, and should stand out from the rests (not noise).\n",
    "        if conv.max()>threshold:\n",
    "            center = int(np.argmax(conv)-self.window.size/2 + left_bound)\n",
    "            return center\n",
    "        else:\n",
    "            print(\"No enough pixels detected\")\n",
    "\n",
    "        return -1\n",
    "\n",
    "    def channel_decompose(self, img, saturation_white_thresh=(0, 2),\n",
    "                         saturation_yellow_thresh=(100, 180),\n",
    "                         hue_thresh=(18, 25), value_thresh=(200, 255),\n",
    "                         component_limit=6, min_area=1000,\n",
    "                         ksize=15):\n",
    "\n",
    "\n",
    "        # Convert to HLS color space and separate the V channel\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "        h_channel = hsv[:,:,0]\n",
    "        s_channel = hsv[:,:,1]\n",
    "        v_channel = hsv[:,:,2]\n",
    "\n",
    "        v_binary = np.zeros_like(v_channel)\n",
    "        v_binary[(v_channel>=value_thresh[0])&(v_channel<=value_thresh[1])] = 1\n",
    "        #\n",
    "        # r_channel = img[:,:,0]\n",
    "        # r_binary = topo_parabolic_bump_filter(cv2.GaussianBlur(r_channel,(5,5),0),\n",
    "        #                                       x_thresh=(0.9,1), min_area=1000, ksize=ksize)\n",
    "        #\n",
    "        # h_binary = np.zeros_like(h_channel)\n",
    "        # h_binary[(h_channel>=hue_thresh[0])&(h_channel<=hue_thresh[1])] = 1\n",
    "        #\n",
    "        # sw_binary = np.zeros_like(s_channel)\n",
    "        # sw_binary[(s_channel>=saturation_white_thresh[0])&(s_channel<=saturation_white_thresh[1])] = 1\n",
    "        # sy_binary = np.zeros_like(s_channel)\n",
    "        # sy_binary[(s_channel>=saturation_yellow_thresh[0])&(s_channel<=saturation_yellow_thresh[1])] = 1\n",
    "\n",
    "        self.thresholds = [50]\n",
    "\n",
    "        return [v_binary]\n",
    "\n",
    "#         return [v_binary, r_binary,h_binary,sw_binary,sy_binary]\n",
    "#         return [v_channel*v_binary, r_channel*r_binary,h_channel*h_binary,\n",
    "#                 s_channel*sw_binary,s_channel*sy_binary]\n",
    "\n",
    "    def prepare_channels(self, img):\n",
    "        channels = self.channel_decompose(img)\n",
    "        self.channels = [im*self.mask for im in channels] #ignore outside of masked region\n",
    "        return len(channels)\n",
    "\n",
    "    def find_window_per_level(self, image, center, level, threshold):\n",
    "        # Find the best centroid by using past center as a reference\n",
    "        min_index = max(center-self.margin, 0)\n",
    "        max_index = min(center+self.margin, self.width)\n",
    "        v_projection = np.sum(image[int(self.height-(level+1)*self.window_height):\n",
    "                                    int(self.height-level*self.window_height),\n",
    "                                    min_index:max_index],\n",
    "                              axis=0)\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        conv_signal = np.convolve(self.window, v_projection)\n",
    "        peak_idx = np.argmax(conv_signal)\n",
    "\n",
    "        # Update window center only if pixels in that slot exceed our threshold\n",
    "        if (conv_signal[peak_idx]>threshold and\n",
    "            len(np.where(conv_signal>conv_signal[peak_idx]/2))<conv_signal.size/2):\n",
    "            # Use window_width/2 as offset because convolution signal reference is at right side of window,\n",
    "            # not center of window\n",
    "            center = peak_idx+min_index+int(self.window_width/2)\n",
    "        return center\n",
    "\n",
    "    def get_points_in_window(self, image, level, window_center):\n",
    "        points = np.zeros_like(image)\n",
    "        if window_center>=0:\n",
    "            window_mask = self.window_mask(window_center,level)\n",
    "            points = image*window_mask\n",
    "        return points\n",
    "\n",
    "    def init_lane_finder(self, side):\n",
    "        idx = -1\n",
    "        center = -1\n",
    "        # search window center starting from the first channel\n",
    "        # for the current channel, locate the bin with most pixels within the given bound\n",
    "        # bounds are different for left lane and right, and are defined in the initializer.\n",
    "        while center<0 and idx<len(self.channels)-1:\n",
    "            idx += 1 # move to the next channel if cannot find a window with peak in this channel\n",
    "            center = self.initial_window_finder(self.channels[idx],self.thresholds[idx],\n",
    "                                                self.lane_bound[side][0], self.lane_bound[side][1],\n",
    "                                                self.lane_bound[side][2], self.lane_bound[side][3])\n",
    "\n",
    "        self.window_centroids[side].append((idx, center))\n",
    "        points = np.zeros((self.height, self.width))\n",
    "        if center>=0:\n",
    "            # when a window with peak is found\n",
    "            # slice the birdview image into several layers and search for peak in each layer.\n",
    "            for level in range(1,self.level_num):\n",
    "                center = self.find_window_per_level(self.channels[idx], center,\n",
    "                                                    level, self.thresholds[idx])\n",
    "                level_points = self.get_points_in_window(self.channels[idx], level, center)\n",
    "                points = np.maximum(points,level_points)\n",
    "                self.window_centroids[side].append((idx, center))\n",
    "        else:\n",
    "            print(\"Could not find a peak window to start with in all channels\")\n",
    "        if side==0:\n",
    "            (self.lane.left_y, self.lane.left_x) = np.where(points>0)\n",
    "            self.lane.polyfit_left()\n",
    "        else:\n",
    "            (self.lane.right_y, self.lane.right_x) = np.where(points>0)\n",
    "            self.lane.polyfit_right()\n",
    "\n",
    "    def tube_lane_finder(self, img, side):\n",
    "        tube_mask = np.zeros_like(img)\n",
    "        if side==0: # left lane\n",
    "            search_radius = 10\n",
    "            while (search_radius<self.margin and\n",
    "                   self.lane.left_x.size<self.left_lane_pixel_thres):\n",
    "                tube_mask[np.abs(self.idx-np.repeat([self.lane.left_fitx],\n",
    "                                           self.width,axis=0).T)<search_radius]=1\n",
    "                l_points = img*tube_mask\n",
    "                (self.lane.left_y, self.lane.left_x) = np.where(l_points>0)\n",
    "                search_radius += 10\n",
    "\n",
    "            return self.lane.polyfit_left()\n",
    "\n",
    "        else:  # right lane\n",
    "            search_radius = 10\n",
    "            while (search_radius<self.margin and\n",
    "                   self.lane.right_x.size<self.right_lane_pixel_thres):\n",
    "                tube_mask[np.abs(self.idx-np.repeat([self.lane.right_fitx],\n",
    "                                               self.width,axis=0).T)<search_radius]=1\n",
    "                r_points = img*tube_mask\n",
    "                (self.lane.right_y, self.lane.right_x) = np.where(r_points>0)\n",
    "                search_radius += 10\n",
    "\n",
    "            return self.lane.polyfit_right()\n",
    "\n",
    "    def draw_lane(self):\n",
    "        # Draw the lane pixels and lane curve\n",
    "        left_bound_idx, right_bound_idx = None, None\n",
    "        if self.lane.left_x.size>0:\n",
    "            # Make left lane pixels blue\n",
    "            self.lane.canvas[self.lane.left_y,self.lane.left_x,2] = 255\n",
    "        if self.lane.left_detected:\n",
    "            # Draw polynomial\n",
    "            self.lane.canvas[self.lane.ploty,self.lane.left_fitx,0:2] = 255\n",
    "            left_bound_idx = np.repeat([self.lane.left_fitx],\n",
    "                                        self.width,axis=0).T\n",
    "        if self.lane.right_x.size>0:\n",
    "            #right lane pixels red,\n",
    "            self.lane.canvas[self.lane.right_y,self.lane.right_x,0] = 255\n",
    "        if self.lane.right_detected:\n",
    "            self.lane.canvas[self.lane.ploty,self.lane.right_fitx,0] = 255\n",
    "            self.lane.canvas[self.lane.ploty,self.lane.right_fitx,2] = 255\n",
    "            right_bound_idx = np.repeat([self.lane.right_fitx], self.width,axis=0).T\n",
    "        elif left_bound_idx is not None:\n",
    "            right_bound_idx = left_bound_idx + self.lane.width\n",
    "\n",
    "        if (left_bound_idx is not None) and (right_bound_idx is not None):\n",
    "            self.lane.canvas[(self.idx-left_bound_idx>0)&(self.idx-right_bound_idx<0),1] = 50\n",
    "        return self.lane.canvas\n",
    "\n",
    "    def draw_result(self, original_img):\n",
    "        new_img = np.copy(original_img)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        text_v_position = 70\n",
    "        for text in self.texts:\n",
    "            cv2.putText(new_img, text, (40, text_v_position),\n",
    "                        font, 1.0, (200,255,155), 2, cv2.LINE_AA)\n",
    "            text_v_position += 30\n",
    "\n",
    "        return new_img\n",
    "\n",
    "    def pipeline(self, img):\n",
    "        # reset information for the current frame\n",
    "        self.lane.reset_canvas()\n",
    "        self.texts = []\n",
    "        self.window_centroids = [[],[]]\n",
    "\n",
    "        # undistort and apply perspective transformation to get birdview\n",
    "        warped_img = cv2.undistort(img, self.calibration_matrix, self.calibration_dist,\n",
    "                                   None, self.calibration_matrix)\n",
    "        warped_img = cv2.warpPerspective(warped_img, self.M,\n",
    "                                         (self.height,self.width),\n",
    "                                         flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # apply different filters to create candidate channels\n",
    "        L = self.prepare_channels(warped_img)\n",
    "#         return np.dstack((self.channels[0],self.channels[0],self.channels[0]))\n",
    "\n",
    "        text = ''\n",
    "        # If lane-line is detected from the previous frame,\n",
    "        # then use tube_lane_finder\n",
    "        if self.lane.left_detected and self.lane.left_fitx is not None:\n",
    "            channel_left_idx = 0\n",
    "            while channel_left_idx<L and (not self.tube_lane_finder(self.channels[channel_left_idx],0)):\n",
    "                channel_left_idx += 1\n",
    "            text += 'L channel:' + str(channel_left_idx)+' pix:'+ str(self.lane.left_x.size) + ', '\n",
    "        else: # otherwise search from scratch\n",
    "            text += 'L init '\n",
    "            self.init_lane_finder(side=0)\n",
    "\n",
    "        # same process applied to right lane-line\n",
    "        if self.lane.right_detected and self.lane.right_fitx is not None:\n",
    "            channel_right_idx = 0\n",
    "            while channel_right_idx<L and (not self.tube_lane_finder(self.channels[channel_right_idx],1)):\n",
    "                channel_right_idx += 1\n",
    "            text += 'R channel:' + str(channel_right_idx)+' pix:'+ str(self.lane.right_x.size)\n",
    "        else:\n",
    "            text += 'R init '\n",
    "            self.init_lane_finder(side=1)\n",
    "\n",
    "        if len(text)>0: self.texts.append(text)\n",
    "\n",
    "        if (self.lane.left_x.size>0) and (self.lane.right_x.size>0):\n",
    "            # compute curvature and center offset\n",
    "            (curvature, center_offset) = self.lane.analyze()\n",
    "            self.texts.append(\"Curvature: \"+\"{:04.1f}\".format(curvature) + 'm')\n",
    "            self.texts.append(\"Distance from Center: \"+\"{:04.3f}\".format(center_offset)+ 'm')\n",
    "\n",
    "        return self.draw_lane()\n",
    "        overlay = cv2.warpPerspective(self.draw_lane(), self.M_inv,\n",
    "                                      (self.original_image_size[1],self.original_image_size[0]),\n",
    "                                      flags=cv2.INTER_LINEAR)\n",
    "        return self.draw_result(cv2.addWeighted(img, 1, overlay, 1, 0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e872e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = cv2.imread(\"test_images/test3.jpg\")\n",
    "print(test_img.shape)\n",
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "res = lane_finder.pipeline(test_img)\n",
    "plt.imshow(res)\n",
    "mpimg.imsave(\"out.png\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'project_video.mp4'\n",
    "output = input_vid[:-4]+\"_output.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'challenge_video.mp4'\n",
    "output = input_vid[:-4]+\"_overlay_polyfinder_curvature.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_finder = LaneFinder((720,1280), mask_vertices, anchor_points, tranformed_image_size, \n",
    "                         mtx, dist, PIX2XM, PIX2YM, window_width=50, window_height=80, margin=100)\n",
    "\n",
    "input_vid = 'harder_challenge_video.mp4'\n",
    "output = input_vid[:-4]+\"_overlay_polyfinder_curvature.mp4\"\n",
    "clip2 = VideoFileClip(input_vid)\n",
    "# clip2 = clip2.subclip(36)\n",
    "challenge_clip = clip2.fl_image(lane_finder.pipeline)\n",
    "%time challenge_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "clip = (VideoFileClip(\"project_video_channels/project_video_channel_0.mp4\")\n",
    "        .resize(0.2))\n",
    "clip.speedx(3).write_gif(\"channel0.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip = VideoFileClip('myanimation.gif') # can be gif or movie\n",
    "for frame in clip.iter_frames():\n",
    "    mpimg.imsave(\"channel0.png\",frame)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
